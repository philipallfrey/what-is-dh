---
layout: song
title: Topic Modelling
original: Duck Tales Theme (Disney)
youTube: https://www.youtube.com/watch?v=nqZ_Cb2slBw
album: vol-01
description: "A #DigitalHumanities song inspired by the Duck Tales theme song"
---

<p>Need some help with distant reading? <a id="note-01" href="#notes-01">1</a><br/>
Topic modelling!<br/>
“Race cars, lasers, aeroplanes”<br/>
That’s a topic <a id="note-02" href="#notes-02">2</a></p>

<p>It works for fishery <a id="note-03" href="#notes-03">3</a><br/>
And legal history <a id="note-04" href="#notes-04">4</a><br/>
Topic modelling!<br/>
Woo-hoo!<br/>
Texts are combinations of N topics <a id="note-05" href="#notes-05">5</a><br/>
Woo-hoo!<br/>
Find out the proportions with statistics</p>

<p>D-D-Dirichlet allocation <a id="note-06" href="#notes-06">6</a><br/>
Is useful for this situation<br/>
How to use it?<br/>
Read the ProgHist lesson <a id="note-07" href="#notes-07">7</a><br/>
Woo-hoo!</p>

<p><abbr title="MAchine Learning for LanguagE Toolkit">MALLET</abbr> gives you keywords in a table<br/>
Woo-hoo!<br/>
Which you must interpret and hand-label <a id="note-08" href="#notes-08">8</a><br/>
Woo-hoo!</p>

<p>Then run again, with different N <a id="note-09" href="#notes-09">9</a><br/>
To cross-check<br/>
Woo-hoo!</p>

<h3>Notes</h3>
<ol class="text-list">
  <li id="notes-01">“Distant reading ... is set in opposition to the form of literary analysis known as close reading. Instead of focusing on textual minutiae, distant reading focuses on the generalities of a text or texts, often via computational means.”<br/>
  Scott B. Weingart, Susan Grunewald, Matthew Lincoln et al. (eds.). The Digital Humanities Literacy Guidebook. Carnegie Mellon University, updated April 03, 2022. <a href="https://cmu-lib.github.io/dhlg/topics/#topic_distantreading" target="_blank">https://cmu-lib.github.io/dhlg/topics/#topic_distantreading</a>  <a class="back" href="#note-01">Back to text</a></li>
  <li id="notes-02">Topic modelling calculates the probability that each word in a text belongs to a topic. A common form of output is the list of top keywords for each topic. <a class="back" href="#note-02">Back to text</a></li>
  <li id="notes-03">Osmar J Luiz, et al, “Trait-based ecology of fishes: A quantitative assessment of literature trends and knowledge gaps using topic modelling”, Fish and Fisheries (2019) 20, 1100–1110 <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/faf.12399" target="_blank">https://onlinelibrary.wiley.com/doi/abs/10.1111/faf.12399</a> <a class="back" href="#note-03">Back to text</a></li>
  <li id="notes-04">P. Grajzl and P. Murrell, “Using Topic-Modeling in Legal History, with an Application to Pre-Industrial English Case Law on Finance”. Law and History Review (2022), 40(2), 189-228. <a href="https://doi.org/10.1017/S0738248022000153" target="_blank">https://doi.org/10.1017/S0738248022000153</a> <a class="back" href="#note-04">Back to text</a></li>
  <li id="notes-05">Topic modelling assumes that the each text in a corpus is made up of a mixture of N possible topics. The number N must be chosen by the modeller. Different values for N will result in different topics. <a class="back" href="#note-05">Back to text</a></li>
  <li id="notes-06">Latent Dirichlet Allocation (LDA) is a popular algorithm for topic modelling. It was introduced in David M. Blei, Andrew Y. Ng, and Michael I. Jordan. “Latent dirichlet allocation”. Journal of Machine Learning Research (2003) 3, 993–1022. <a href="https://dl.acm.org/doi/10.5555/944919.944937" target="_blank">https://dl.acm.org/doi/10.5555/944919.944937</a> <a class="back" href="#note-06">Back to text</a></li>
  <li id="notes-07">The Programming Historian (<a href="https://twitter.com/ProgHist" target="_blank">@ProgHist</a> on Twitter) has a tutorial on how to use MALLET, a popular topic modelling tool. It is not necessary to fully understand the LDA algorithm to use MALLET. Shawn Graham, Scott Weingart, and Ian Milligan, "Getting Started with Topic Modeling and MALLET," Programming Historian 1 (2012), <a href="https://doi.org/10.46430/phen0017" target="_blank">https://doi.org/10.46430/phen0017.</a> <a class="back" href="#note-07">Back to text</a></li>
  <li id="notes-08">Each topic in a topic model need manual evaluation to determine whether it is a coherent topic (not a statistical artifact), and if so what it represents.<a class="back" href="#note-08">Back to text</a></li>
  <li id="notes-09">The optimal number of topics will depend on the size of the corpus, and the research question. While there are statistical methods for choosing a number, usually it is simpler to run a topic model with different numbers of topics, and compare the output. See e.g. Maria Antoniak, Topic Modelling for the People (2022) <a href="https://maria-antoniak.github.io/2022/07/27/topic-modeling-for-the-people.html#test-different-numbers-of-topics" target="_blank">https://maria-antoniak.github.io/2022/07/27/topic-modeling-for-the-people.html#test-different-numbers-of-topics</a> <a class="back" href="#note-09">Back to text</a></li>
</ol>
